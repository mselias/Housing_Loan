{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System libraries\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Database Connector\n",
    "import pymysql\n",
    "\n",
    "# Data Manipulator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cometic library\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Accesory Libraries\n",
    "import time\n",
    "\n",
    "# Import Custom Library\n",
    "import CompData as cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_Name = ['application_test.csv', 'bureau.csv', \n",
    "            'credit_card_balance.csv', 'previous_application.csv', \n",
    "            'POS_CASH_balance.csv', 'application_train.csv', 'bureau_balance.csv', \n",
    "            'installments_payments.csv', 'sample_submission.csv']\n",
    "\n",
    "Table_Name = [i.replace('.csv', '').replace('_', ' ') for i in CSV_Name]\n",
    "\n",
    "Table_Name = ['{0}'.format([k.capitalize() \n",
    "                            for k in i.split(' ')]).replace(\"['\", '')\\\n",
    "                                     .replace(\"', '\", '_').replace(\"']\", '') \n",
    "              for i in Table_Name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(Table):\n",
    "    \n",
    "    Query = '''\n",
    "\n",
    "    SELECT * \n",
    "    FROM {0}\n",
    "    LIMIT 3;\n",
    "    \n",
    "    '''.format(Table)\n",
    "    \n",
    "    return pd.read_sql_query(Query, connector)\n",
    "\n",
    "def colextract(self):\n",
    "    Structure = pd.DataFrame(data = (list(self.columns), list(self.dtypes)),\n",
    "                             index = ['colnames', 'dtypes'])\n",
    "    Structure = Structure.T\n",
    "    Structure['dtypes'] = np.where(Structure['dtypes'] == 'object', 'VARCHAR(200)', Structure['dtypes'])\n",
    "    Structure['dtypes'] = np.where(Structure['dtypes'] == 'float64', 'FLOAT', Structure['dtypes'])\n",
    "    Structure['dtypes'] = np.where(Structure['dtypes'] == 'int64', 'BIGINT', Structure['dtypes'])\n",
    "    Structure['Concat'] = ['{0} {1}'.format(Structure.iloc[i,0], Structure.iloc[i,1]) for i in range(len(Structure))]\n",
    "\n",
    "    Columns = str(tuple(Structure['Concat']))\n",
    "    return Columns.replace(\"'\", \"\")\n",
    "\n",
    "def table_creator(Table_Name, Columns):\n",
    "    \n",
    "    Drop_Table = '''\n",
    "\n",
    "    DROP TABLE IF EXISTS {0};\n",
    "\n",
    "    '''.format(Table_Name)\n",
    "\n",
    "    Create_Table = '''\n",
    "\n",
    "    CREATE TABLE {0} \n",
    "    {1};\n",
    "\n",
    "    '''.format(Table_Name, Columns)\n",
    "    \n",
    "    gen_db = connector.cursor()\n",
    "    Status_Drop = gen_db.execute(Drop_Table)\n",
    "    Status_Create = gen_db.execute(Create_Table)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('Drop Status: {0}'.format(Status_Drop), '\\nCreate Status: {0}'.format(Status_Create))\n",
    "    \n",
    "    gen_db.close()\n",
    "    \n",
    "def to_mysql(File, Table):\n",
    "    \n",
    "    variables = tuple('@{0}'.format(i.replace(' BIGINT', '').replace(' VARCHAR(200)', '')\\\n",
    "                                    .replace('FLOAT', '').replace('(', '').replace(')', ''))\n",
    "                      for i in Columns[File].split(', '))\n",
    "    variable = str(variables).replace(\"'\", '')\n",
    "\n",
    "    set_variable = list(i.replace('(', '').replace(')', '')\\\n",
    "                        .replace(' BIGINT', \" = NULLIF({0}, '')\".format(j))\\\n",
    "                        .replace(' VARCHAR200', \" = NULLIF({0}, '')\".format(j))\\\n",
    "                        .replace('FLOAT', \" = NULLIF({0}, '')\".format(j))\n",
    "                        for i, j in zip(Columns[File].split(', '), variables))\n",
    "\n",
    "    set_variable = str(set_variable).replace('\"', '').replace('[', '').replace(']', '')\n",
    "    \n",
    "    Loading_Data = '''\n",
    "\n",
    "    LOAD DATA LOCAL INFILE \"/Users/bicboi/Desktop/Work/Housing_Loan/home-credit-default-risk/{0}\"\n",
    "    INTO TABLE {1}\n",
    "    COLUMNS TERMINATED BY ','\n",
    "    OPTIONALLY ENCLOSED BY '\"'\n",
    "    ESCAPED BY '\"'\n",
    "    LINES TERMINATED BY '\\n'\n",
    "    IGNORE 1 LINES\n",
    "    {2}\n",
    "    SET {3};\n",
    "\n",
    "    '''.format(File, Table, variable, set_variable)\n",
    "    \n",
    "    Compress_Table = '''\n",
    "    \n",
    "    OPTIMIZE TABLE {0};\n",
    "    \n",
    "    '''.format(Table)\n",
    "    \n",
    "    load_data = connector.cursor()\n",
    "    Status_Load = load_data.execute(Loading_Data)\n",
    "    \n",
    "    compress_data = connector.cursor()\n",
    "    load_data.execute(Compress_Table)\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    print('Status: Pass\\n# Of Rows: {0}'.format(Status_Load))\n",
    "    \n",
    "    load_data.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Columns To Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = {}\n",
    "\n",
    "for i in CSV_Name:\n",
    "    \n",
    "    Testing = pd.read_csv('home-credit-default-risk/{0}'.format(i),nrows = 1)\n",
    "\n",
    "    Columns[i] = colextract(Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = tuple('@{0}'.format(i.replace(' BIGINT', '').replace(' VARCHAR(200)', '')\\\n",
    "                                .replace('FLOAT', '').replace('(', '').replace(')', ''))\n",
    "                  for i in Columns['application_test.csv'].split(', '))\n",
    "variable = str(variables).replace(\"'\", '')\n",
    "\n",
    "set_variable = list(i.replace('(', '').replace(')', '')\\\n",
    "                    .replace(' BIGINT', \" = NULLIF({0}, '')\".format(j))\\\n",
    "                    .replace(' VARCHAR200', \" = NULLIF({0}, '')\".format(j))\\\n",
    "                    .replace('FLOAT', \" = NULLIF({0}, '')\".format(j))\n",
    "                    for i, j in zip(Columns['application_test.csv'].split(', '), variables))\n",
    "\n",
    "set_variable = str(set_variable).replace('\"', '').replace('[', '').replace(']', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring MySQL Connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling in Credentials\n",
    "Credentials = eval(pd.read_csv(Cred_Path, header = None).iloc[0,0])\n",
    "\n",
    "# Establishing Connection\n",
    "connector = pymysql.connect(port = Credentials['port'],\n",
    "                            user = Credentials['user'], passwd = Credentials['pass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop DataBase And Recreate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropper = connector.cursor()\n",
    "Drop_DB = '''\n",
    "\n",
    "DROP DATABASE IF EXISTS Housing;\n",
    "\n",
    "'''\n",
    "Dropper.execute(Drop_DB)\n",
    "Dropper.close()\n",
    "\n",
    "Creator = connector.cursor()\n",
    "Create_DB = '''\n",
    "\n",
    "CREATE DATABASE Housing;\n",
    "\n",
    "'''\n",
    "Creator.execute(Create_DB)\n",
    "Creator.close()\n",
    "\n",
    "connector.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-Esthablish Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing Connection\n",
    "connector = pymysql.connect(port = Credentials['port'],\n",
    "                            user = Credentials['user'], passwd = Credentials['pass'],\n",
    "                            db = 'Housing', charset = 'utf8mb4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n",
    "### Creating Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop Status: 0 \n",
      "Create Status: 0\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(Columns.values(), Table_Name):\n",
    "    table_creator(j, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ending Connection first\n",
    "connector.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-establishing Connection\n",
    "connector = pymysql.connect(port = Credentials['port'],\n",
    "                            user = Credentials['user'], passwd = Credentials['pass'],\n",
    "                            autocommit = True, local_infile = 1,\n",
    "                            db = 'Housing', charset = 'utf8mb4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connector.cursor().execute('SET GLOBAL local_infile = 1;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: Pass\n",
      "# Of Rows: 48744\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(CSV_Name, Table_Name):\n",
    "    print(j)\n",
    "    to_mysql(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in Table_Name:\n",
    "    \n",
    "    print(connector.cursor().execute('OPTIMIZE TABLE {0};'.format(i)))\n",
    "    \n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connector.cursor().execute('SET GLOBAL local_infile = 0;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable_name</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>local_infile</td>\n",
       "      <td>OFF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable_name Value\n",
       "0  local_infile   OFF"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('SHOW VARIABLES LIKE \"local_infile\";', connector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
